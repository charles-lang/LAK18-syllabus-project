---
title: "There must be bugs :-("
author: "Sam and Ben"
date: "August 23, 2017"
output: html_document
---
## Load libraries
```{r}


library(NLP)
library(SnowballC)
library(tm)
library(wordcloud)

library(ggplot2)
library(dplyr)
library(tidyr)
library(topicmodels)
library(tidytext)

```

## Load and pre-process corpus
```{r}
#It looks like there is more than one syllubus in this document, that means there is no variation to find between documents. When I run the code below it looks like there are no topics, this could be the reason. I would try to separate the syllabi into individual text documents and then load the whole folder.
docs<-Corpus(VectorSource("syllabi.txt"))

toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, content_transformer(tolower))

docs <- tm_map(docs, removeNumbers)

docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("student", "students", "will","grade","course","final","instructor","fall","summer","spring","incomplete","project","email"))
docs <- tm_map(docs, removeWords, c("the","a","how","when", "where", "it", "an", "whose", "and","are", "at", "as", "be", "by", "for", "from", "has"))
docs <- tm_map(docs, removeWords, c("in", "is", "its", "of", "on", "that", "was", "were", "will", "with", "whom", "but", "or","to","grades","courses","semester"))
docs <- tm_map(docs, removeWords, c("about", "am" ,"any", "aren't", "at","because", "both", "can't", "couldn't", "did", "didn't", "do", "does","doesn't","doing"))
docs <- tm_map(docs, removeWords, c("don't, 'have", "had","haven't", "haveing", "how","isn't","its", "of","or","such", "than", "that", "that's"))


docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)

```


## Create TDM
```{r}
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)

v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)

```

# Run LDA to define topics
```{r}
ap_lda <- LDA(m, k = 2, control = list(seed = 123))

terms(ap_lda)
topics(ap_lda)

```


```{r}

ap_topics <- tidy(ap_lda, matrix = "beta")



ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder(term, beta))
  ggplot(aes(term, beta, fill = factor(topic))) +
  #geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()                    

```

# Predict topics for new syllabus
```{r}
topics <- posterior(ap_lda,new.syl)
(syl.topics <- apply(topics$topics, 1, which.max))
```

# Choose one word to represent each topic
```{r}

```

#Generate matrix of topic words and 

# Use neural net to match to learning goal or objective
```{r}
library(neuralnet)

net <- neuralnet(verbs ~ topics, DF, hidden = 1, threshold = 0.01)
```

